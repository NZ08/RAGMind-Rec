import pandas as pd
import json
from typing import Dict, Any, Optional
import os
from pathlib import Path


class ProductBatchGenerator:
    """äº§å“æ•°æ®æ‰¹å¤„ç†ç”Ÿæˆå™¨
    
    ç”¨äºå°†CSVæ ¼å¼çš„äº§å“æ•°æ®è½¬æ¢ä¸ºAIæ‰¹å¤„ç†è¯·æ±‚çš„JSONLæ ¼å¼æ–‡ä»¶ã€‚
    æ”¯æŒå¤šæ¨¡æ€æ•°æ®å¤„ç†ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰ï¼Œé€‚ç”¨äºRAGæ£€ç´¢ç³»ç»Ÿã€‚
    """
    
    def __init__(self, temperature: float = 0.5):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            temperature: AIæ¨¡å‹çš„æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
        """
        self.temperature = temperature
        self.system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†å“ä¿¡æ¯åˆ†æåŠ©æ‰‹ï¼Œ"
            "æ“…é•¿ä»å•†å“çš„æ–‡æœ¬æè¿°å’Œå›¾åƒä¸­æå–æ ¸å¿ƒç‰¹å¾å¹¶ä½¿ç”¨è‹±æ–‡å›ç­”ã€‚"
        )
    
    def _create_prompt_template(self, product_data: Dict[str, Any]) -> str:
        """åˆ›å»ºç”¨äºAPIè°ƒç”¨çš„æç¤ºè¯æ¨¡æ¿
        
        Args:
            product_data: äº§å“æ•°æ®å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        prompt = f"""Task: Combine the text information and images of the following goods to extract the core features for RAG retrieval, taking into account the text attributes and image visual details.

Product text information:
"asin": "{product_data.get('asin', '')}",
"description": "{product_data.get('description', '')}",
"title": "{product_data.get('title', '')}",
"price": {product_data.get('price', '')},
"brand": "{product_data.get('brand', '')}"

Requirements:
1. Features not specified in the supplementary text but observable in the image;
2. Infer the implied attributes of the text;
3. It is presented in short sentences of "dimension+specific content", without redundancy, highlighting high-frequency keywords;
4. The output JSON format should include asin, brand of the product, description of the product, title of the product, price of the product, target customer portrait, and brief description (such as schoolbag, pacifier, milk powder, etc.). All field contents should not be bracketed.
5. If the description, title, price and brand fields of the original product information are empty or do not exist, you can omit them from the output JSON.
6. You can add other fields according to the actual situation, but they should be useful for product information."""
        return prompt
    
    def _create_message_content(self, product_data: Dict[str, Any]) -> list:
        """åˆ›å»ºæ¶ˆæ¯å†…å®¹åˆ—è¡¨ï¼ŒåŒ…å«æ–‡æœ¬å’Œå›¾åƒ
        
        Args:
            product_data: äº§å“æ•°æ®å­—å…¸
            
        Returns:
            æ¶ˆæ¯å†…å®¹åˆ—è¡¨
        """
        content = []
        
        # æ·»åŠ æ–‡æœ¬å†…å®¹
        text_content = {
            "type": "text",
            "text": self._create_prompt_template(product_data)
        }
        content.append(text_content)
        
        # æ·»åŠ å›¾åƒå†…å®¹ï¼ˆå¦‚æœå­˜åœ¨æœ‰æ•ˆçš„å›¾åƒURLï¼‰
        image_url = product_data.get('imUrl', '').strip()
        if image_url:
            image_content = {
                "type": "image_url",
                "image_url": {
                    "url": image_url,
                    "detail": "high"  # é«˜ç»†èŠ‚æ¨¡å¼ï¼Œæ›´å¥½åœ°ç†è§£å›¾åƒç»†èŠ‚
                }
            }
            content.append(image_content)
        
        return content
    
    def _create_batch_request(self, product_data: Dict[str, Any], request_id: str) -> Dict[str, Any]:
        """åˆ›å»ºå•ä¸ªæ‰¹å¤„ç†è¯·æ±‚
        
        Args:
            product_data: äº§å“æ•°æ®å­—å…¸
            request_id: è¯·æ±‚ID
            
        Returns:
            æ‰¹å¤„ç†è¯·æ±‚å­—å…¸
        """
        messages = [
            {
                "role": "system",
                "content": self.system_prompt
            },
            {
                "role": "user",
                "content": self._create_message_content(product_data)
            }
        ]
        
        return {
            "custom_id": request_id,
            "body": {
                "messages": messages,
                "thinking": {
                    "type": "disabled"
                },
                "temperature": self.temperature
            }
        }
    
    @staticmethod
    def _safe_get_value(row: pd.Series, key: str) -> str:
        """å®‰å…¨è·å–DataFrameè¡Œä¸­çš„å€¼
        
        Args:
            row: pandas Serieså¯¹è±¡
            key: å­—æ®µå
            
        Returns:
            å­—ç¬¦ä¸²å€¼ï¼Œå¦‚æœä¸ºç©ºæˆ–NaNåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        value = row.get(key, '')
        return '' if pd.isna(value) else str(value)
    
    def _extract_product_data(self, row: pd.Series) -> Dict[str, str]:
        """ä»DataFrameè¡Œä¸­æå–äº§å“æ•°æ®
        
        Args:
            row: pandas Serieså¯¹è±¡
            
        Returns:
            äº§å“æ•°æ®å­—å…¸
        """
        return {
            'asin': self._safe_get_value(row, 'asin'),
            'description': self._safe_get_value(row, 'description'),
            'title': self._safe_get_value(row, 'title'),
            'price': self._safe_get_value(row, 'price'),
            'imUrl': self._safe_get_value(row, 'imUrl'),
            'brand': self._safe_get_value(row, 'brand')
        }
    
    def generate_batch_files(self, 
                           csv_file_path: str, 
                           output_dir: str = "./data", 
                           batch_size: int = 10000,
                           file_prefix: str = "batch") -> bool:
        """å°†CSVæ•°æ®æŒ‰æ‰¹æ¬¡è½¬æ¢ä¸ºJSONLæ ¼å¼æ–‡ä»¶
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            batch_size: æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®é‡
            file_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
            
        Returns:
            æ˜¯å¦æˆåŠŸç”Ÿæˆæ‰€æœ‰æ–‡ä»¶
        """
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶
            csv_path = Path(csv_file_path)
            if not csv_path.exists():
                raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # è¯»å–CSVæ–‡ä»¶
            print(f"æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {csv_file_path}")
            df = pd.read_csv(csv_file_path)
            total_rows = len(df)
            
            if total_rows == 0:
                print("è­¦å‘Š: CSVæ–‡ä»¶ä¸ºç©º")
                return True
            
            print(f"æˆåŠŸè¯»å–CSVæ–‡ä»¶ï¼Œå…±{total_rows:,}è¡Œæ•°æ®")
            
            # è®¡ç®—æ‰¹æ¬¡æ•°
            num_batches = (total_rows + batch_size - 1) // batch_size
            print(f"å°†åˆ†æˆ{num_batches}ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æ¬¡æœ€å¤š{batch_size:,}æ¡æ•°æ®")
            
            # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
            for batch_num in range(num_batches):
                start_row = batch_num * batch_size
                end_row = min(start_row + batch_size, total_rows)
                current_batch_size = end_row - start_row
                
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
                output_file = output_path / f"{file_prefix}_{batch_num + 1:03d}.jsonl"
                
                print(f"æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {batch_num + 1}/{num_batches}ï¼Œ"
                      f"æ•°æ®èŒƒå›´: {start_row:,}-{end_row-1:,} ({current_batch_size:,}æ¡)")
                
                # å†™å…¥æ‰¹æ¬¡æ–‡ä»¶
                with open(output_file, 'w', encoding='utf-8') as f:
                    for index, row in df.iloc[start_row:end_row].iterrows():
                        # æå–äº§å“æ•°æ®
                        product_data = self._extract_product_data(row)
                        
                        # åˆ›å»ºæ‰¹å¤„ç†è¯·æ±‚
                        request_id = f"request-{index + 1}"
                        batch_request = self._create_batch_request(product_data, request_id)
                        
                        # å†™å…¥JSONLæ–‡ä»¶
                        f.write(json.dumps(batch_request, ensure_ascii=False) + '\n')
                
                print(f"âœ“ æˆåŠŸç”Ÿæˆæ‰¹æ¬¡æ–‡ä»¶: {output_file} ({current_batch_size:,}æ¡è®°å½•)")
            
            print(f"\nğŸ‰ æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
            print(f"   - æ€»è®¡: {num_batches}ä¸ªæ–‡ä»¶")
            print(f"   - æ•°æ®é‡: {total_rows:,}æ¡è®°å½•")
            print(f"   - ä¿å­˜ä½ç½®: {output_path.absolute()}")
            return True
            
        except FileNotFoundError as e:
            print(f"âŒ æ–‡ä»¶é”™è¯¯: {e}")
            return False
        except pd.errors.EmptyDataError:
            print(f"âŒ CSVæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {csv_file_path}")
            return False
        except Exception as e:
            print(f"âŒ ç”ŸæˆJSONLæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False


def main():
    """ä¸»å‡½æ•° - é…ç½®å‚æ•°å¹¶æ‰§è¡Œæ‰¹å¤„ç†ç”Ÿæˆ"""
    # é…ç½®å‚æ•°

    # æœ¬ä»£ç æ–‡ä»¶ä»¥åè¦ä¿®æ”¹æˆä¸“é—¨çš„jsonæ ¼å¼ï¼Œè€Œä¸æ˜¯ç”¨æç¤ºè¯å‘Šè¯‰ä»–ç”Ÿæˆjsonæ ¼å¼
    config = {
        'csv_file_path': "d:\\WorkSpace\\RAGRec\\meta.csv",
        'output_dir': "./data",
        'batch_size': 10000,
        'temperature': 0.5,
        'file_prefix': "batch"
    }
    
    print("=" * 60)
    print("ğŸš€ äº§å“æ•°æ®æ‰¹å¤„ç†ç”Ÿæˆå™¨")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {config['csv_file_path']}")
    print(f"è¾“å‡ºç›®å½•: {config['output_dir']}")
    print(f"æ‰¹æ¬¡å¤§å°: {config['batch_size']:,}")
    print(f"æ¸©åº¦å‚æ•°: {config['temperature']}")
    print("-" * 60)
    
    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
    generator = ProductBatchGenerator(temperature=config['temperature'])
    
    # æ‰§è¡Œæ‰¹å¤„ç†ç”Ÿæˆ
    success = generator.generate_batch_files(
        csv_file_path=config['csv_file_path'],
        output_dir=config['output_dir'],
        batch_size=config['batch_size'],
        file_prefix=config['file_prefix']
    )
    
    if success:
        print("\nâœ… æ‰€æœ‰JSONLæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
    else:
        print("\nâŒ JSONLæ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()