import pandas as pd
import json
from typing import Dict, Any, List
import os
from pathlib import Path


class ProductFeatureBatchGenerator:
    """å•†å“ç‰¹å¾æ•°æ®æ‰¹å¤„ç†ç”Ÿæˆå™¨
    
    ç”¨äºå°†CSVæ ¼å¼çš„ç”¨æˆ·è´­ä¹°æ•°æ®è½¬æ¢ä¸ºAIæ‰¹å¤„ç†è¯·æ±‚çš„JSONLæ ¼å¼æ–‡ä»¶ã€‚
    ä¸“é—¨å¤„ç†contentã€descriptionã€priceã€TCP-ç›®æ ‡å®¢æˆ·æè¿°ã€brief_descriptionã€titleå­—æ®µä¸­çš„ç®¡é“ç¬¦åˆ†éš”æ•°æ®ã€‚
    """
    
    def __init__(self, temperature: float = 0.5):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            temperature: AIæ¨¡å‹çš„æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
        """
        self.temperature = temperature
        self.system_prompt = (
            "You are a professional product analysis assistant, "
            "skilled at analyzing user purchase history and extracting product feature keywords for recommendation systems."
        )
    
    def _format_pipe_separated_content(self, content: str, field_name: str) -> str:
        """å°†ç®¡é“ç¬¦åˆ†éš”çš„å†…å®¹è½¬æ¢ä¸ºå¸¦åºå·çš„å›è½¦ç¬¦åˆ†éš”æ ¼å¼
        
        Args:
            content: ç®¡é“ç¬¦åˆ†éš”çš„å†…å®¹å­—ç¬¦ä¸²
            field_name: å­—æ®µåç§°
            
        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if pd.isna(content) or not content.strip():
            return f"{field_name}: No content"
        
        items = content.split('|')
        
        # ç›´æ¥å»æ‰æœ€åä¸€ä¸ªå…ƒç´ ç”¨äºé¢„æµ‹
        items = items[:-1]
        
        # æ£€æŸ¥æ€»å­—ç¬¦é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡5000åˆ™è¿›è¡Œæˆªæ–­å¤„ç†
        total_length = sum(len(item.strip()) for item in items if item.strip())
        if total_length > 5000:
            items = self._truncate_items(items)
        
        formatted_items = []
        
        for i, item in enumerate(items, 1):
            if item.strip():  # åªå¤„ç†éç©ºé¡¹
                formatted_items.append(f"{i}. {item.strip()}")
        
        if not formatted_items:
            return f"{field_name}: No valid content"
        
        return f"{field_name}:\n" + "\n".join(formatted_items)
    
    def _format_price_content(self, content: str, field_name: str) -> str:
        """ä¸“é—¨å¤„ç†ä»·æ ¼å­—æ®µçš„æ ¼å¼åŒ–
        
        Args:
            content: ç®¡é“ç¬¦åˆ†éš”çš„ä»·æ ¼å†…å®¹å­—ç¬¦ä¸²
            field_name: å­—æ®µåç§°
            
        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if pd.isna(content) or not content.strip():
            return f"{field_name}: No content"
        
        items = content.split('|')
        formatted_items = []
        
        for i, item in enumerate(items, 1):
            if item.strip():  # åªå¤„ç†éç©ºé¡¹
                formatted_items.append(f"{i}. {item.strip()}")
        
        if not formatted_items:
            return f"{field_name}: No valid content"
        
        return f"{field_name}:\n" + "\n".join(formatted_items)
    
    def _truncate_items(self, items: List[str]) -> List[str]:
        """æˆªæ–­å†…å®¹é¡¹ç›®ï¼Œæ¯ä¸ªé¡¹ç›®ä¿ç•™å‰750å­—ç¬¦å’Œå750å­—ç¬¦ï¼Œä¸­é—´ç”¨å¥å·è¿æ¥
        
        Args:
            items: åŸå§‹å†…å®¹é¡¹ç›®åˆ—è¡¨
            
        Returns:
            æˆªæ–­åçš„å†…å®¹é¡¹ç›®åˆ—è¡¨
        """
        truncated_items = []
        
        for item in items:
            item = item.strip()
            if not item:
                continue
                
            if len(item) <= 1000:  # å¦‚æœé•¿åº¦ä¸è¶…è¿‡1000ï¼Œä¸éœ€è¦æˆªæ–­
                truncated_items.append(item)
            else:
                # æˆªæ–­ï¼šå‰500å­—ç¬¦ + å¥å· + å500å­—ç¬¦
                front_part = item[:500]
                back_part = item[-500:]
                truncated_item = f"{front_part}.{back_part}"
                truncated_items.append(truncated_item)
        
        return truncated_items
    
    def _create_prompt_template(self, product_data: Dict[str, Any]) -> str:
        """åˆ›å»ºç”¨äºAPIè°ƒç”¨çš„æç¤ºè¯æ¨¡æ¿
        
        Args:
            product_data: å•†å“æ•°æ®å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        # æ ¼å¼åŒ–å„ä¸ªå­—æ®µ
        formatted_content = self._format_pipe_separated_content(
            product_data.get('content', ''), 'Product Content'
        )
        formatted_description = self._format_pipe_separated_content(
            product_data.get('description', ''), 'Product Description'
        )
        formatted_price = self._format_price_content(
            product_data.get('price', ''), 'Product Price'
        )
        formatted_tcp = self._format_pipe_separated_content(
            product_data.get('TCP-ç›®æ ‡å®¢æˆ·æè¿°', ''), 'Target Customer Profile'
        )
        formatted_brief = self._format_pipe_separated_content(
            product_data.get('brief_description', ''), 'Brief Description'
        )
        formatted_title = self._format_pipe_separated_content(
            product_data.get('title', ''), 'Product Title'
        )
        
        prompt = f"""Task: Based on the user's purchase history data, analyze and extract key product feature keywords that represent the characteristics of products this user has purchased.

{formatted_content}

{formatted_description}

{formatted_price}

{formatted_tcp}

{formatted_brief}

{formatted_title}

Requirements:
1. Analyze all the provided product information to understand the user's purchase preferences
2. Extract key product feature keywords that represent the characteristics of purchased products
3. Focus on product attributes, categories, styles, price ranges, cost performance, and target customer characteristics
4. Strictly output results in JSON object format, containing the following field:
   - product_features: Product feature keywords (only keywords, at least 10 keywords and no more than 20 keywords, for example: ["keyword1", "keyword2", "keyword3"])

Please ensure the output is in valid JSON format."""
        return prompt
    
    def _create_batch_request(self, product_data: Dict[str, Any], request_id: str) -> Dict[str, Any]:
        """åˆ›å»ºå•ä¸ªæ‰¹å¤„ç†è¯·æ±‚
        
        Args:
            product_data: å•†å“æ•°æ®å­—å…¸
            request_id: è¯·æ±‚ID
            
        Returns:
            æ‰¹å¤„ç†è¯·æ±‚å­—å…¸
        """
        messages = [
            {
                "role": "system",
                "content": self.system_prompt
            },
            {
                "role": "user",
                "content": self._create_prompt_template(product_data)
            }
        ]
        
        return {
            "custom_id": request_id,
            "body": {
                "messages": messages,
                "response_format": {
                    "type": "json_object"
                },
                "thinking": {
                    "type": "disabled"
                },
                "temperature": self.temperature,
                "max_tokens": 500
            }
        }
    
    @staticmethod
    def _safe_get_value(row: pd.Series, key: str) -> str:
        """å®‰å…¨è·å–DataFrameè¡Œä¸­çš„å€¼
        
        Args:
            row: pandas Serieså¯¹è±¡
            key: å­—æ®µå
            
        Returns:
            å­—ç¬¦ä¸²å€¼ï¼Œå¦‚æœä¸ºç©ºæˆ–NaNåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        value = row.get(key, '')
        return '' if pd.isna(value) else str(value)
    
    def _extract_product_data(self, row: pd.Series) -> Dict[str, str]:
        """ä»DataFrameè¡Œä¸­æå–å•†å“æ•°æ®
        
        Args:
            row: pandas Serieså¯¹è±¡
            
        Returns:
            å•†å“æ•°æ®å­—å…¸
        """
        return {
            'content': self._safe_get_value(row, 'content'),
            'description': self._safe_get_value(row, 'description'),
            'price': self._safe_get_value(row, 'price'),
            'TCP-ç›®æ ‡å®¢æˆ·æè¿°': self._safe_get_value(row, 'TCP-ç›®æ ‡å®¢æˆ·æè¿°'),
            'brief_description': self._safe_get_value(row, 'brief_description'),
            'title': self._safe_get_value(row, 'title')
        }
    
    def generate_batch_files(self, 
                           csv_file_path: str, 
                           output_dir: str = "./data/product-feature-batch", 
                           batch_size: int = 1000,
                           file_prefix: str = "product_feature_batch") -> bool:
        """å°†CSVæ•°æ®æŒ‰æ‰¹æ¬¡è½¬æ¢ä¸ºJSONLæ ¼å¼æ–‡ä»¶
        
        Args:
            csv_file_path: CSVæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            batch_size: æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®é‡
            file_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
            
        Returns:
            æ˜¯å¦æˆåŠŸç”Ÿæˆæ‰€æœ‰æ–‡ä»¶
        """
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶
            csv_path = Path(csv_file_path)
            if not csv_path.exists():
                raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # è¯»å–CSVæ–‡ä»¶
            print(f"æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {csv_file_path}")
            df = pd.read_csv(csv_file_path)
            
            total_rows = len(df)
            
            if total_rows == 0:
                print("è­¦å‘Š: CSVæ–‡ä»¶ä¸ºç©º")
                return True
            
            print(f"æˆåŠŸè¯»å–CSVæ–‡ä»¶ï¼Œå…±{total_rows:,}è¡Œæ•°æ®")
            
            # è®¡ç®—æ‰¹æ¬¡æ•°
            num_batches = (total_rows + batch_size - 1) // batch_size
            print(f"å°†åˆ†æˆ{num_batches}ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æ¬¡æœ€å¤š{batch_size:,}æ¡æ•°æ®")
            
            # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
            for batch_num in range(num_batches):
                start_row = batch_num * batch_size
                end_row = min(start_row + batch_size, total_rows)
                current_batch_size = end_row - start_row
                
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
                output_file = output_path / f"{file_prefix}_{batch_num + 1:03d}.jsonl"
                
                print(f"æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {batch_num + 1}/{num_batches}ï¼Œ"
                      f"æ•°æ®èŒƒå›´: {start_row:,}-{end_row-1:,} ({current_batch_size:,}æ¡)")
                
                # å†™å…¥æ‰¹æ¬¡æ–‡ä»¶
                with open(output_file, 'w', encoding='utf-8') as f:
                    for index, row in df.iloc[start_row:end_row].iterrows():
                        # æå–å•†å“æ•°æ®
                        product_data = self._extract_product_data(row)
                        
                        # åˆ›å»ºæ‰¹å¤„ç†è¯·æ±‚
                        user_id = self._safe_get_value(row, 'UserID')
                        request_id = f"{user_id}"
                        batch_request = self._create_batch_request(product_data, request_id)
                        
                        # å†™å…¥JSONLæ–‡ä»¶
                        f.write(json.dumps(batch_request, ensure_ascii=False) + '\n')
                
                print(f"âœ“ æˆåŠŸç”Ÿæˆæ‰¹æ¬¡æ–‡ä»¶: {output_file} ({current_batch_size:,}æ¡è®°å½•)")
            
            print(f"\nğŸ‰ æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
            print(f"   - æ€»è®¡: {num_batches}ä¸ªæ–‡ä»¶")
            print(f"   - æ•°æ®é‡: {total_rows:,}æ¡è®°å½•")
            print(f"   - ä¿å­˜ä½ç½®: {output_path.absolute()}")
            return True
            
        except FileNotFoundError as e:
            print(f"âŒ æ–‡ä»¶é”™è¯¯: {e}")
            return False
        except pd.errors.EmptyDataError:
            print(f"âŒ CSVæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {csv_file_path}")
            return False
        except Exception as e:
            print(f"âŒ ç”ŸæˆJSONLæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False


def main():
    """ä¸»å‡½æ•° - é…ç½®å‚æ•°å¹¶æ‰§è¡Œæ‰¹å¤„ç†ç”Ÿæˆ"""
    # é…ç½®å‚æ•°
    config = {
        'csv_file_path': "d:\\WorkSpace\\RAGRec\\meta-data\\user_interactions.csv",
        'output_dir': "./data/product-feature-batch",
        'batch_size': 10000,  # æ¯æ‰¹æ¬¡10000ä¸ªæ ·æœ¬
        'temperature': 0.5,
        'file_prefix': "product_feature_batch"
    }
    
    print("=" * 60)
    print("ğŸš€ å•†å“ç‰¹å¾æ•°æ®æ‰¹å¤„ç†ç”Ÿæˆå™¨")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {config['csv_file_path']}")
    print(f"è¾“å‡ºç›®å½•: {config['output_dir']}")
    print(f"æ‰¹æ¬¡å¤§å°: {config['batch_size']:,}")
    print(f"æ¸©åº¦å‚æ•°: {config['temperature']}")
    print("-" * 60)
    
    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
    generator = ProductFeatureBatchGenerator(temperature=config['temperature'])
    
    # æ‰§è¡Œæ‰¹å¤„ç†ç”Ÿæˆ
    success = generator.generate_batch_files(
        csv_file_path=config['csv_file_path'],
        output_dir=config['output_dir'],
        batch_size=config['batch_size'],
        file_prefix=config['file_prefix']
    )
    
    if success:
        print("\nâœ… æ‰€æœ‰JSONLæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
    else:
        print("\nâŒ JSONLæ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()